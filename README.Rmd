---
output:
  github_document:
    toc: true
    toc_depth: 3
    pandoc_args: --webtex
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  cache = TRUE,
  comment = "#>",
  message = FALSE
)
```

# epiwave.mapping

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
<!-- badges: end -->

Prototype R package and example code for computationall-yefficient, fully-Bayesian semi-mechanistic spatio-temporal mapping of disease infection incidence simultaneously from spatially-aggregated (e.g. at health facility level) clinical case count timeseries, and targeted infection prevalence surveys at specific point locations. This model and software is based on ideas in the epiwave R package and uses some functions implemented there, but it currently relies on the user to develop their own model using the greta R package, rather than providing wrapper functions to set up the model for the user.

## Installation

You can install the package from github, using the `remotes` package:

```{r install, eval = FALSE}
remotes::install_github("idem-lab/epiwave.mapping",
                        dependencies = TRUE)
```

## Model

Our main aim is to model, and generate spatio-temporal predictive maps of, variation in *infection incidence*: the average number of new infections per time period, per member of the population. We model the logarithm of infection incidence with a space-time Gaussian process. Since infection incidence is rarely perfectly observed, we infer it from two independent and complementary datastreams:

- **Clinical case timeseries**: Counts of the numbers of cases reported over time, but potentially spatially aggregated across e.g. the catchment areas of health facilities, or the entire region, rather than at spatially precise coordinates

- **Infection prevalence survey points**: Random samples of individuals at a specific point location, with the number tested and number positive recorded. Typically these data are available only very infrequently.

Since neither datastream provides a direct estimate of infection incidence, we model the generative observation process yielding each datastream, using informative priors for key parameters wherever possible. A number of options are available for computationally-efficient space-time Gaussian process (GP) modelling for applications of this type. Below we implement an approach well-suited to our health facility catchment observation model and fully Bayesian inference using Hamiltonian Monte Carlo: a separable space-time GP employing a block-circulant embedding for the spatial process. This is similar to the approach used in the `lgcp` R package, and detailed in Diggle et al. (2013). We note that the clinical incidence observation model we employ is a particular case of a Log-Gaussian Cox process. Our contribution is accounting for delays in reporting, and linking model this to prevalence survey data, in a practical and easily-extensible framework.

### Clinical incidence model 

We model the observed number of clinical cases $C_{h,t}$ of our disease of interest in health facility $h$ during discrete time period $t$ as a Poisson random variable:

$$
C_{h,t} \sim \text{Poisson}(\hat{C}_{h,t})
$$
The expectation of this Poisson random variable (the modelled/expected number of clinical cases) is given by a weighted sum of (unobserved but modelled) expected pixel-level clinical case counts $\hat{C}_{l,t}$ at each of $L$ pixel locations $l$:

$$
\hat{C}_{h,t} = \sum_{l=1}^{L}{\hat{C}_{l,t}w_{l,h}}
$$

where weights $w_{l,h}$ give the 'membership' of the population in each pixel location to each health facility, where each case at a given location $l$ has probability $w_{l,h}$ of reporting at health facility $h$, and therefore $\sum_{l=1}^L w_{l,h} = 1$. In practice this could be either a proportional (fractions of the population attend different health facilities) or a discrete (the population of each pixel location attends only one nearby health facility) mapping.

At each pixel location, we model the unobserved clinical case count $\hat{C}_{l,t}$ from the modelled number of new infections $\hat{I}_{l,t'}$ at the same location, during previous time periods $t'$, from the fraction of infections $\gamma_{l,t'}$ at that location and previous time period that would result in a recorded clinical case, and a probability distribution $\pi(t-t')$ over delays $t-t'$ from infection to diagnosis and reporting:

$$
\hat{C}_{l,t} = \sum_{t-t' = 0}^{\tau_\pi}{\hat{I}_{l,t'} \, \gamma_{l,t'} \, \pi(t-t')}
$$
The distribution $\pi(\Delta_t)$ gives the discrete and finite (support on $\Delta_t \in (0, \tau_\pi)$) probability distribution over delays from infection to reporting, indexed on the time-periods considered in the model. This temporal reweighting to account for a distribution over possible delays can be considered as a 'discrete-time convolution' with $\pi(\Delta_t)$ the 'kernel'. Below we discuss efficient methods for computing these convolutions in greta.

### Infection prevalence model 

We model the observed number of individuals who test positive for infection $N^+_{l,t}$ in an infection prevalence survey at location $l$ at time $t$ as a binomial sample, given the number of individuals tested $N_{l,t}$, and the modelled prevalence of infections $\hat{p}_{l,t}$ across the population at that time/place:

$$
N^+_{l,t} \sim \text{Binomial}(N_{l,t}, \hat{p}_{l,t})
$$
Similarly to clinical incidence, we model the infection prevalence at a given location and time as a discrete-time convolution over previous infection counts, divided by the total population in the pixel $M_l$, and the duration of the time-period in days $d$:

$$
\hat{p}_{l,t} = \frac{1}{M_l}\sum_{t-t' = 0}^{\tau_q}{q(t-t') \, \hat{I}_{l,t'} \, d^{-1}}
$$

In this case, the kernel $q(t-t')$ is not a probability distribution, but the kernel of a convolution operation that maps the daily average number of new infections in previous time periods $t'$ to the number of individuals who would test positive (to the diagnostic used) on a randomly-selected day in the timeperiod `t`. This kernel, which is specific to the tim eperiod chosen for modelling the temporal process, can be computed from a related function: $q_{\text{daily}}(\Delta_t)$ which gives the probability that an individual will test positive $\Delta_t$ days after infection. The integral of this function is the average number of days an infected person would test positive for. The function $q_{\text{daily}}()$ can be estimated from empirical data on how the test sensitivity and duration of infection vary over time since infection. This package provides functionality: `transform_convolution_kernel()` to construct timeperiod-specific kernels such as $q()$ from daily kernels like $q_{\text{daily}}()$ for an arbitrary modelling timeperiod.

By convolving of the number of new infections *per day* $\hat{I}_{l,t'} \, d^{-1}$ in all previous time periods with the fraction of those that would test positive in a survey in time period $t$, gives an estimate of the *number* of positive-testing people in the population at location $l$, on any given day within the time period $t$. Dividing this by the population of that location, $M_l$, therefore yields an estimate of the population proportion testing positive on any given day; the parameter of the binomial distribution that captures the prevalence survey data.

Note that our definition of $\hat{p}_{l,t}$ is the population prevalence of infections *that would test positive using that diagnostic method* rather than the true fraction infected/infectious at any one time. We also assume here that tests have perfect specificity, though the model can easily be adapted to situations where that is not the case.

### Infection incidence model 

The expected number of new infections $\hat{I}_{l,t'}$ in location $l$ during time period $t$ is modelled as the product of the population $M_l$ at that location, the length of the timeperiod in days $d$, and the daily infection incidence $f_{l,t}$ at that location and time:

$$
\hat{I}_{l,t'} = d \, M_l \, \hat{f}_{l,t}
$$

Whilst we mechanistically model the observation processes yielding our data types, we employ a geostatistical approach to modelling spatio-temporal variation in infection incidence, with spatio-temporal covariates $\mathbf{X}_{l,t}$ and a space-time random effect $\epsilon_{l,t}$ with zero-mean Gaussian process prior:

$$
\text{log}(f_{l,t}) = \alpha +\mathbf{X}_{l,t} \beta + \epsilon_{l,t}
$$

$$
\epsilon \sim GP(0, \mathbf{K})
$$

where $\alpha$ is a scalar intercept term, $\beta$ is a vector of regression coefficients against the environmental covariates, and $\mathbf{K}$ is the space-time covariance function of the Gaussian process over random effects $\epsilon_{l,t}$.

There are many choices of space-time covariance structure for $\mathbf{K}$, though we use a separable combination of an isotropic spatial covariance function with a temporal covariance function, to enable the use of a range of computationally efficient simulation and calculation methods:

$$
K_{l,t,l',t'} = \sigma^2 \, K_{\text{space}}(||l-l'||; \phi) \, K_{\text{time}}(|t-t'|; \theta)
$$
where $\sigma^2$ is the marginal variance (amplitude) of the resultant Gaussian process, $K_{\text{space}}(.; \phi)$ is an (unit variance) isotropic spatial kernel on euclidean distances $||l-l'||$ with parameter $\phi > 0$ controlling the range of spatial correlation, and $K_{\text{time}}(|t-t'|; \theta)$ is a a temporal kernel on time differences $|t-t'|$, with parameter $\theta$ controlling the range of temporal correlation. Again for computational reasons, we prefer Markovian kernels for $K_{\text{time}}$.

### Infection prevalence - clinical incidence relationship

As described above, the spatially- and temporally-varying parameter $\gamma_{l,t}$  gives the fraction of new infections that would result in a recorded clinical case. In the absence of additional data to that described above, it is unlikely that spatio-temporal variation in this parameter can be inferred. For some diseases - e.g. those where previous infections confer little immune protection from symptoms of future infections - it may be sufficient to model this as a constant, in which case it can be inferred statistically. However for many diseases, there is likely to be a non-linear relationship between the infection incidence in a given population, and the fraction of those infections that result in a clinical case. Where repeat infections decrease the clinical severity of subsequent infections, $\gamma_{l,t}$ is likely to manifest as a monotone decreasing function of infection incidence $f_{l,t}$. In this scenario, it would be preferable to account for this relationship using external information. In the case of malaria, this relationship is often explored using empirical data in terms of the relationship between infection prevalence and clinical incidence. Where a previously-estimated relationship between infection prevalence and clinical incidence is available, the relationship between infection incidence and clinical incidence can be inferred as follows.

We assume that a pre-determined function $g()$ is available that maps from the 'true' population infection prevalence $p_{i}$ to the 'true' underlying clinical incidence $c_{i}$ in some population and setting $i$, for which the corresponding infection incidence is held constant:

$$
c_{i} = g(p_{i})
$$

In this case, $c_{i}$ gives the incidence of all clinical episodes regardless whether those cases would be recorded in a health system. We therefore assume that $g()$ is estimated against empirical estimates of $p_{i}$ and of $c_{i}$ that would be observed under some intensive surveillance (e.g. a prospective study), or other high-quality source of information. We therefore capture imperfect reporting in the health system under which observed case counts $C_{i}$ are collected via some constant reporting rate $r$:

$$
C_{i} = r \, d \, M_i \, c_{i}
$$
where $d$ is the duration of time periods over which the counts are made, and $M_i$ is the size of this population (converting from clinical incidence to the number of clinical cases, as above). Under the assumption (from $g()$) that infection incidence $f_{i}$ is constant over the period to which $c_{i}$ and $p_{i}$ correspond, these two quantities can therefore be related as:

$$
c_{i} = \kappa_i f_{i}
$$
where $\kappa_i$ is the fraction of infections at location $i$ resulting in a clinical case (recorded or otherwise), and:
$$
p_{i} = q^* \, f_{i}
$$
where $q^*$ is the average number of subsequent days on which each new infection would test positive, if tested once per day (following from the convolution above, in the case that $f_{l,t}$ and therefore $I_{l,t}$ are constant over time); the integral of the detectability function $q()$: 
$$
q^* = \int_{0}^{\tau_q}{q(t) dt}
$$
This scalar value $q^*$ can equally be interpretted as the average number of previous days worth of infections that are detected on the day of a prevalence survey. In practice, $q^*$ can be estimated by a sufficiently-fine resolution discrete sum over $q(t)$.

Combining the above, we have that:

$$
c_i = \kappa_i \, f_i = g(q^* f_i)
$$
and therefore:
$$
\kappa_i = g(q^* f_i) / f_i
$$
simce $\gamma_i = r \, \kappa_i$, and applying this relationship to our spatio-temporally varying infection incidences $f_{l,t}$, we can compute $\gamma_{l,t}$ as:
$$
\gamma_{l,t} = r \, g(q^* f_{l,t}) \, / \, f_{l,t}
$$

where $q^*$ is a scalar constant that can be computed *a priori* from $q$, $g()$ is a deterministic function, also known *a priori*, $f_{l,t}$ is our inference target, the daily infection incidence, and $r$ is the only remaining free parameter in this relationship, which is identifiable in the model.

In practice, the functional form of $g()$ may well permit the computational complexity of this term to be reduced, either by computing a simpler analytic solution, or approximating it with a functionally simpler form with near-equivalent shape. This will likely aid in reducing the computational cost of fitting the model.

## Computational approaches

### Inference

We fit the model via fully Bayesian inference, using MCMC (Hamiltonian Monte Carlo) in the greta R package. Whilst a number of alternative inference algorithms have been proposed and widely adopted for Bayesian and non-Bayesian estimation of spatio-temporal Gaussian process models (e.g. INLA), in out case, the aggregation of clinical cases across catchments (a feature required by the model structure) leads to a non-factorising likelihood, which nullifies many of the computational advantages of that method. Further, the mapping from the Gaussian process to the expectations of the two sampling distributions is non-linear (due to sums of exponents in various places), requiring computationally costly linearisation of the non-linearities. By employing a fully-Bayesian MCMC approach, and focussing on computationally-efficient model and implementation choices, rather than approximations, we are able to estimate the model parameters relatively quickly, with full treatment, propagation, and quantification of model uncertainty, and retaining the ability to easily modify and interrogate the model.

### Discrete-time convolution

This discrete convolutions (weighted sums over previous time points) used to compute $\hat{C}_{l,t}$ and $\hat{p}_{l,t}$ can be computationally intensive, depending on the number of time periods modelled. A number of efficient computational approaches exist to overcome these, and the optimal approach to use in greta depends on the size of $\tau^{max}$: the maximum duration of the delay in terms of the number of timeperiods being considered. Where $\tau^{max}$ is relatively large (say, $\tau^{max} > 3$), implementation of the convolution as a matrix multiply is likely to be the most efficient in greta. If $\tau^{max} > 3$ and the number of time periods being modelled is much larger than $\tau^{max}$, implementing this as a sparse matrix multiply (skipping computation on zero elements of the convolution matrix) is likely to be most efficient. Where $\tau^{max}$ is small (say, $\tau^{max} \leq 3$) the convolution can instead be computed with a sum of dense vectorised additions and subtractions. These convolution approaches are implemented in this package, and demonstrated below.

### Gaussian process simulation

Naive implementation of the full Gaussian process (GP) model is typically very computationally intensive, due to the fact that the most expensive step (inverting a dense covariance matrix) scales cubically with the number of evaluation points. In the model we propose (and as in a Log-Gaussian Cox process), we need to evaluate the GP at every pixel location and time period in the study frame, so that we can aggregate the expected clinical case count to compute the likelihood. This results in a computationally impractical algorithm for all but the smallest study frames.

One solution would be to employ an approximation to the full GP, evaluated at only a subset of locations and times in the study frame, and approximating the clinical case count calculation with some smaller finite sum. Candidate GP approximation approaches include the SPDE approximation to a Matern-type spatial kernel, on a computational mesh (as used in INLA, Lindgren *et al.*, 2011), a sparse GP method over a limited set of inducing points (Quinonera-Candela *et al.*, ?; see `greta.gp`), or one of the closely-related penalised spline methods (see `greta.gam`).

An appealing alternative in this case is to compute the full spatial GP for every pixel in a regular grid (the same we use to record spatial covariate values), by exploiting the block-circulant structure in the resulting spatial covariance matrix. This requires using projected coordinates, and expanding the spatial study frame (by a factor of 2 in each dimension) to map the projection onto a torus in such a way that the distances between pairs of pixels are preserved. This approach enables simulation of the GP across all pixels, for a given time period, via the fast fourier transform (FFT) - which scales only linearly with the number of locations considered (? check when have wifi). This enables us to simulate values of the spatial GP across all pixels very cheaply, with no need to approximate the GP. In separable combination with a Markovian temporl kernel, this enables very rapid inference. 

## Example application

We demonstrate the model with application to mapping the (simulated) infection incidence of malaria in Kenya from simulated clinical incidence and infection prevalence data. Using the `sim_data()` function from this package, we use a real grid of environmental covariates, but simulate the locations of health facilities, prevalence survey locations, and all datasets to which we will then fit the model.

### Simulating data

First we load the bioclim covariates using the `terra` and `geodata` R package:
```{r bioclim, eval = FALSE}
library(terra)
library(geodata)
# download at a half-degree resolution. See ?geodata_path for how to save the data between sessions
bioclim_kenya <- geodata::worldclim_country(
  country = "KEN",
  var = "bio",
  res = 0.5,
  path = file.path(tempdir(), "bioclim")
)

pop <- geodata::population(
  year = 2020,
  res = 0.5,
  path = file.path(tempdir(), "population")
)

# crop and mask to Kenya
pop_kenya <- mask(pop, bioclim_kenya)

```

```{r bioclim_secret, eval = TRUE, echo = FALSE}
library(terra)
library(geodata)
# I'm on a plane writing this, so mocking up the chunk with a file I know I have
source_bioc <- "../vector_atlas_training_2024/data/rasters/bc_kenya.tif"
bioclim_kenya <- rast(source_bioc)
source_pop <- "../ir_cube/data/clean/pop_cube.tif"

kenya_mask <- bioclim_kenya[[1]]
pop <- rast(source_pop)$pop_2020
pop_kenya <- crop(pop, kenya_mask)
disagg_factor <- 5
pop_kenya <- terra::disagg(pop_kenya, disagg_factor) / (disagg_factor ^ 2)
pop_kenya <- resample(pop_kenya, kenya_mask)
pop_kenya <- mask(pop_kenya, kenya_mask)
```

Now we lower the spatial resolution a little (to make the example run faster) and simulate some fake data, using the first 5 covariates:
```{r sim_data}

# aggregate rasters
bioclim_kenya_lores <- terra::aggregate(bioclim_kenya, 10)
pop_kenya_lores <- terra::aggregate(pop_kenya, 10)

# set time periods
start_year <- 2020
n_years <- 5

# subset and scale the bioclim layers to make our covariates
covariates_lores <- scale(bioclim_kenya_lores[[1:5]])

# simulate fake data
library(epiwave.mapping)
set.seed(1)
data <- sim_data(
  covariates_rast = covariates_lores,
  population_rast = pop_kenya_lores, 
  years = seq(start_year, start_year + n_years - 1),
  n_health_facilities = 60,
  n_prev_surveys = 30,
  # assume some fraction of case counts are missing
  case_missingness = 0.3)
```

Let's visualise the fake data.

Plot the fake health facility locations over the population raster:

```{r vis_data_1}
library(tidyverse)
library(tidyterra)

# plot the health facility locations
ggplot() +
  geom_spatraster(data = pop_kenya_lores) +
  scale_fill_gradient(
    low = grey(0.9),
    high = grey(0.6),
    transform = "log1p",
    na.value = "transparent",
    guide = "none") +
  geom_point(
    aes(
      y = y,
      x = x
    ),
    data = data$surveillance_information$health_facilities$health_facility_loc,
    shape = 16
  ) +
  xlab("") +
  ylab("") +
  theme_minimal() +
  ggtitle("Health facility locations")
```

Plot the clinical case timeseries for all health facilities over each year:

```{r vis_data_2}

# add months and years onto the clinical cases, for plotting
cases <- data$epi_data$clinical_cases %>%
  mutate(
    month = 1 + (time - 1) %% 12,
    year = start_year + (time - 1) %/% 12,
    health_facility = factor(health_facility)
  )

ggplot(
  aes(
    x = month,
    y = cases,
    colour = health_facility,
    group = health_facility
  ),
  data = cases) +
  facet_wrap(~year) +
  geom_line(
    linewidth = 0.3
  ) + 
  theme_minimal() +
  scale_colour_discrete(
    guide = "none"
  ) +
  scale_x_continuous(breaks = 1:12) +
  ggtitle("Clinical case timeseries")
```

Plot the prevalence survey results at the prevalence survey locations:

```{r vis_data_3}
prev_surveys <- data$epi_data$prevalence_surveys %>%
  mutate(
    prevalence = n_positive / n_sampled
  )

ggplot() +
  geom_spatraster(data = pop_kenya_lores) +
  scale_fill_gradient(
    low = grey(0.9),
    high = grey(0.9),
    na.value = "transparent",
    guide = "none") +
  geom_point(
    aes(
      y = y,
      x = x,
      colour = prevalence
    ),
    data = prev_surveys,
    size = 3,
    shape = 16
  ) +
  scale_colour_gradient(
    labels = scales::label_percent(),
    low = "skyblue",
    high = "darkred"
  ) +
  xlab("") +
  ylab("") +
  theme_minimal() +
  ggtitle("Prevalence surveys")

```

Plot the fake delay distribution (probability mass function over days) and prevalence survey detectability functions:

```{r vis_data_4}
case_delay_plot <- tibble(
  days = seq(0, data$surveillance_information$case_delay_max_days)) %>%
  mutate(
    pmf = data$surveillance_information$case_delay_distribution_daily_fun
(days)
  )

ggplot(
  aes(x = days,
      y = pmf),
  data = case_delay_plot) +
  geom_step() +
  theme_minimal() +
  ggtitle("Case reporting delay distribution",
          "Probability of reporting X days after infection")
```

```{r vis_data_5}
detectability_plot <- tibble(
  days = seq(0, data$surveillance_information$prev_detectability_max_days)) %>%
  mutate(
    detectability = data$surveillance_information$prev_detectability_daily_fun
(days)
  )

ggplot(
  aes(x = days,
      y = detectability),
  data = detectability_plot) +
  geom_step() +
  theme_minimal() +
  ggtitle("Prevalence survey detectability function",
          "Probability of registering a positive if tested X days after infection")
```

Plot the assumed infection prevalence - clinical case incidence relationship:

```{r vis_data_6}
prev_inc_plot <- tibble(prevalence = seq(0, 0.5, length.out = 100)) %>%
  mutate(
    clinical_incidence = data$surveillance_information$prev_inc_function
(prevalence)
  )

ggplot(
  aes(x = prevalence,
      y = 365 * clinical_incidence),
  data = prev_inc_plot) +
  geom_line() +
  theme_minimal() +
  xlab("Prevalence") +
  ylab("Clinical incidence (annual)") +
  ggtitle("Prevalence - clinical incidence function")
```

### Model specification using greta

To specify the model in greta, first we define all free model hyperparameters (ie. all parameters except for the spatiotemporal random effects `epsilon`). Here we use an arbitrary set of priors, that happen to be those used to simulate the 'true' parameters in `epiwave.mapping::sim_data()`. In a pracctical application, the user should give these a lot more thought. 
```{r define_priors}
library(greta)

# intercept and slope for fixed-effects terms on daily infection incidence
alpha <- normal(log(1e-4), 1)
beta <- normal(0, 1, dim = terra::nlyr(covariates_lores))
# fraction of all clinical cases reported in case counts
r <- beta(10, 5)
# variance, spatial correlation range, and temporal correlation of epsilon
sigma <- beta(12, 8)
phi <- beta(16, 4)
theta <- beta(18, 2)
```

We can use functions from `epiwave.mapping` to define the model for the spatio-temporal random effect epsilon, using the block-circulant basis approach. To do so, we first need to ensure that the raster we use to define this computational setup is appropriately projected, so that we can make a reasonable assumption that the grid of cells is regularly spaced in both dimensions:

```{r project_rasters}
# define a mask raster - 0 in land cells, NA elsewhere
kenya_mask_lores <- pop_kenya_lores * 0

# Pick projectionas UTM zone 36S (Uganda, Kenya, Tanzania)
new_crs <- "epsg:21036"

# project the raster to set up our grid
grid_raster <- terra::project(kenya_mask_lores, new_crs)

# also project the covariates
covariates_raster <- terra::project(covariates_lores, new_crs)
```

Now we can define the objects required for the block-circulant basis approach to simulating IID Guassian processes over space, and converting them to spatio-temporal Gaussian processes: 

```{r define_bcb, eval = FALSE}
bcb_setup <- define_bcb_setup(grid_raster)
```

Now we can define a space-time Gaussian process over `epsilon`, by first defining our isotropic spatial kernel, using the greta.gp R package, and the Markovian temporal kernel by passing the parameters to `epiwave.mapping`:
```{r define_gp, eval = FALSE}
library(greta.gp)

# to define an isotropic kernel in greta.gp, we need to repeat phi for both
# dimensions. We set the variance to 1, since we define that at the level of the
# space-time kernel

# use a penalised complexity prior here, as per INLA
k_space <- mat52(lengthscales = c(phi, phi),
                 variance = 1)

# pass this to the function to create space-time GPs over all cells
epsilon <- sim_bcb_gp(
  bcb_setup = bcb_setup,
  n_times = n_years * 12,
  space_kernel = k_space,
  time_correlation = theta,
  sigma = sigma
)
```
Now we have the object or the spatio-temporal random effects, and all our other parameters, we can define the deterministic mapping from these, through infection incidence, to our observed data. First we compute the daily incidence of new infections, per cell, per timestep.

```{r define_infection_incidence, eval = FALSE}

# get an index to all pixel values
all_cells <- terra::cells(kenya_mask_lores)

# extract the covariate design matrix (scale)
X <- extract(covariates_lores, all_cells)

# matrix-multiply with beta, and add alpha, to get the spatial fixed effects
fixef <- alpha + X %*% beta

# add on epsilon, and convert to infection incidence
eta <- sweep(epsilon, 1, fixef, FUN = "+")
infection_incidence <- ilogit(eta)

# multiply by population and timeperiod to get the count of new infections per time period
timeperiod_days <- 365/12
pop_all_cells <- extract(pop_kenya_lores, all_cells)

new_infections <- infection_incidence * pop_all_cells * timeperiod_days
```   

Compute expected prevalence at prevalence survey locations

Compute expected reported cases at all pixels

Aggregate expected reported cases at health facilities

Define likelihoods - accounting for missingness in clinical cases

### Model fitting and prediction

Run MCMC

Make pixel-level posterior prediction maps of infection incidence, clinical incidence, prevalence

Aggregate these up to district-level posterior summaries

### Comparison with simulated truth

Compare side-by-side with 'true' simulated surfaces from the `data` object
